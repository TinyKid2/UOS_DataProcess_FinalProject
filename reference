주제

임의의 데이터를 선정하여

(ETL) 수집, 변환, 적재 파이프라인 구성

시나리오 서술 및 소감 작성



필수 서술사항

사용한 데이터의 설명

데이터 플로우 디자인



주의사항

UI 필요하지 않으니 UI구현에 너무 집중하지 마시기 바랍니다





예시

=============================================

예시

1. 사용한 데이터

- 이미지핸들링 수강생들로부터 제출받은 YOLO모델 weight파일과 제출 ID

- 제출ID는 임의의 UUID로 구성되어 있으며 weight파일은 binary 형태로 구성되어 있음



2. 데이터 플로우 디자인 고려사항

- 다음의 두가지 중에서 고민

1) weight파일을 로컬 evaluation 노드에서 다운로드 받아서 진행

-> 데이터 흐름상 클라우드 인스턴스 아웃바운트 트래픽을 과도하게 유발

2) weight파일 대신 weight파일이 업로드된 google 드라이버 경로를 제출받음

-> 수강생의 개인공간을 사용하도록 강요하는 상황이 됨

※ 1개의 weight파일이 10MB미만임에 따라 최종적으로 1)로 결정



3. 데이터 플로우 디자인

■ 수집

- 순서1: 프로토타입 형태의 웹사이트로부터 수집: 수강생측의 파일 업로드 및 서버측의 UUID 발행

- 순서2: Kafka Producer1

   - Apache NiFi의 도입: GetFile 컴포넌트를 사용하면 서버에서 로그로만 남겨주면 됨

   - Topic이름: model_submission

   - { id: 1234-4567-123123123, file: test.pt}



■ 변환

- 순서3: Kafka Consumer1

   - Evaluation node에 구성: 위의 model_submission을 구독 

   - 위의 file을 다운로드 후 ultralytics로 evaluation진행

   - 평가 결과를 아래와 같이 기록

   - { id: 1234-4567-123123123, file: test.pt, f1:90.4, precision:93.2, recall:88.3}

  

- 순서4: Kafka Producer2

   - Evaluation node에 구성: 위의 평가 결과 파일이 기록된 디렉토리에 NiFi GetFile컴포넌트 사용하도록

   - Evaluation node로부터 클라우드 서버로 결과 전송



■ 적재 

- 순서5: Kafka Consumer2

   - 클라우드 서버에 구성되어 Evaluation결과를 mariadb에 적재

   

3. (Optional) 결과의 serving

- 상기 1의 웹서버에서 QueryID를 받아서 해당 QueryID에 대응되는 평가결과를 mariadb로부터 조회하여 반환





■ 느낀점

- 실제로 구현해보고 하나씩 꺼봤는데 영향이 없이 서빙이 잘 되고 있었다

- 기존에 구현했던 데이터 ETL 체계의 시행착오를 보완할 수 있는 계기가 되었으면 좋겠다

